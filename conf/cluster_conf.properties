################################################################################
## Copyright:   HZGOSUN Tech. Co, BigData
## Filename:    cluster_conf.properties
## Description: 一键配置集群脚本的配置文件
## Version:     1.0
## Author:      mashencai && caodabao
## Created:     2017-12-8
################################################################################

#---------------------------------------------------------------------#
#                              使用说明                                #
#---------------------------------------------------------------------#

# 一键配置脚本从这个配置文件根据key关键字读取需要修改的配置，
# 例如根据关键字[ZOOKEEPER]读取[ZOOKEEPER=]后的内容，并将该内容配入相应的文件。

# 【格式】
# 键与值之间用[等号=]分割，例如ZOOKEEPER=172.18.18.106:2181
# 同一个键的值之间用[分号;]分割，例如172.18.18.106:2181;172.18.18.107:2181

# 【配置方法】
# 进行配置时，只需修改“key=”key等号之后的内容即可。
# 有多余的ip号等在后面追加，并注意用[分号;]分割。
# 注意：不能更改key！！

#---------------------------------------------------------------------#
#                              密码配置                                #
#---------------------------------------------------------------------#
#一般为默认，不建议修改。

# ssh登录到其他节点时的密码
SSH_Password=123456

MYSQL_Password=Hzgc@123

#---------------------------------------------------------------------#
#                              集群配置                                #
#---------------------------------------------------------------------#

#  集群所有节点主机名，用于在所有节点之间实现xcall和xsync工具；配置ssh免密码登录；关闭防火墙；
#  安装基础工具expectRpm，mysqlRpm，dos2unix；安装jdk
#  e.x:s115;s116;s117
Cluster_HostName=

#  需要配置分发算法库的节点：e.x:s115;s116;s117
GsFaceLib_HostName= 

#----------------------------HADOOP组件安装配置---------------------------#

# 【HDFS安装节点】
#  目前支持ha模式，需要配置两个节点作为主备节点；
#  除namenode之外的节点可以配置datanode，
#  如果需要在namenode上启动datanode，请在安装hadoop后执行hadoop-damenon.sh start datanode；
#  主备节点：e.x:s115;s116
Hadoop_NameNode=
#  数据存储节点：e.x:s116;s117
Hadoop_DataNode=

# 【yarn】
#  除ResourceManager之外的节点可以配置datanode;如果需要在namenode上启动datanode yarn-dameon.sh start nodemanager
#  资源管理和调度节点：e.x:s115;s116
Yarn_ResourceManager=
#  执行任务节点：e.x:s116;s117
Yarn_NodeManager=
#  Yarn 的NodeManager 的个数
Yarn_NumOfNodeManger=

#----------------------------HIVE组件安装配置---------------------------#
#  安装节点：e.x:s115;s116;s117
Meta_ThriftServer=

#  安装了mysql的节点：e.x:s115(这是集群安装包所在节点，mysqlInstall.sh在该节点执行)
Mysql_InstallNode=

#----------------------------HBASE组件安装配置---------------------------#
#  主节点(高可用节点)：e.x:s116（主节点只有一个节点）
HBase_Hmaster=
#  从节点：e.x:s115;s117
HBase_HRegionServer=

#----------------------------ES组件安装配置---------------------------#
#  安装节点：e.x:s115;s116;s117
ES_InstallNode=

#----------------------------Kafka组件安装配置---------------------------#
#  安装节点：e.x:s115;s116;s117
Kafka_InstallNode=

#----------------------------RocketMQ组件安装配置---------------------------#
#  主节点：e.x:s117（主节点只有一个节点）
RocketMQ_Namesrv=
#  从节点：e.x:s115;s116
RocketMQ_Broker=

#----------------------------ZOOKEEPER组件安装配置---------------------------#
#  安装节点：e.x:s115;s116;s117
Zookeeper_InstallNode=

#----------------------------SPARK组件安装配置---------------------------#
#  主节点：e.x:s115（主节点只有一个节点）
Spark_NameNode=
# 从节点：e.x:s116;s117
Spark_ServiceNode=

#----------------------------HAproxy组件安装配置---------------------------#
#  代理节点：e.x:s116（代理节点只有一个节点）
HAproxy_AgencyNode=
#  服务节点：e.x:s115;s117
HAproxy_ServiceNode=

#----------------------------Scala组件安装配置---------------------------#
#  安装节点：e.x:s115;s116;s117
Scala_InstallNode=

#---------------------------------------------------------------------#
#                              目录配置                                #
#---------------------------------------------------------------------#
#一般为默认，不建议修改。

## Source文件所在目录:(用于source 大数据环境变量)
Source_File=/opt/hzgc/env_bigdata.sh

## 一些系统额外需要的配置安装路径，比如expectRpm，mysqlRpm，dos2unix
System_SuportDir=/opt/hzgc/basic_suports

## 大数据相关的组件安装根目录
Install_HomeDir=/opt/hzgc/bigdata

## Source文件、集群服务启动和停止的文件目录:
Cluster_ServiceDir=/opt/hzgc/service

## 集群组件的日志文件目录:
Cluster_LOGSDir=/opt/hzgc/logs

## WebUI地址存放目录：
WebUI_Dir=/opt/hzgc
